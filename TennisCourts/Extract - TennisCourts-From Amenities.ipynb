{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the Survey File\n",
    "#surveyData = pd.read_csv(\"C:\\Projects\\MSS\\Loading _AmenityData_from_Survey\\Test.csv\",sep=\",\" , skiprows=1)\n",
    "surveyData = pd.read_csv(\"C:\\Projects\\MSS\\Loading _AmenityData_from_Survey\\AmenityClubSurvey FINAL v2 Season Cleaned_deletedFirstTwoColumn.csv\",sep=\",\" , skiprows=1)\n",
    "surveyData.head()\n",
    "\n",
    "## Reading the Config File and Extracting the Information from there\n",
    "config_file = open(\"C:\\Projects\\MSS\\Loading _AmenityData_from_Survey\\Python_Codes\\ClubCorp\\DiningRoom\\diningColMapping.json\")\n",
    "dinningRoom_config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToDayTimeMap (phonebook, key, value):\n",
    "    if key in phonebook:\n",
    "        x =  phonebook[key]\n",
    "        phonebook[key] = x + \",\" + value\n",
    "        \n",
    "    else :\n",
    "        phonebook[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareHoursOfOperationJson(hoursOfOperationInfo, surveyData, isFirstDiningRoom, columnIndexIncreaseCountFor2ndDining):\n",
    "    \n",
    "    allHoursOfOperation = []\n",
    "    \n",
    "    for i in range(0, len(surveyData)) : \n",
    "        hoursOfOperationForEachRow = []\n",
    "        hoursOfOperation = {}\n",
    "        hoursOfOperationValue = {}\n",
    "\n",
    "        season = \"All Season\"\n",
    "        ## adding season value\n",
    "        if season and not pd.isnull(season):\n",
    "            seasonValue = {}\n",
    "            seasonValue[\"value\"] = season\n",
    "            hoursOfOperationValue[\"Season\"] = [seasonValue]\n",
    "        \n",
    "        \n",
    "        ## creating day time map so that days with same open and closed time can handled properly\n",
    "        dayTimeMap = {}    \n",
    "        for j in range(0, len(hoursOfOperationInfo)):\n",
    "            \n",
    "            dayInfo = hoursOfOperationInfo[j]\n",
    "            day = dayInfo[\"Day\"]\n",
    "            openTimeIndex = dayInfo[\"OpenTime\"]\n",
    "            closeTimeIndex = dayInfo[\"CloseTime\"]\n",
    "            \n",
    "            if not isFirstDiningRoom :\n",
    "                openTimeIndex = openTimeIndex+  columnIndexIncreaseCountFor2ndDining;\n",
    "                closeTimeIndex = closeTimeIndex+  columnIndexIncreaseCountFor2ndDining;\n",
    "                \n",
    "            startTimeRaw = surveyData.iat[i, openTimeIndex]\n",
    "            endTimeRaw = surveyData.iat[i, closeTimeIndex]\n",
    "            \n",
    "            startTime = \"\"\n",
    "            endTime = \"\"\n",
    "            if pd.notnull(startTimeRaw):\n",
    "                startTime = str(startTimeRaw).strip()\n",
    "            \n",
    "            if pd.notnull(endTimeRaw):\n",
    "                endTime = str(endTimeRaw).strip()\n",
    "                \n",
    "            \n",
    "            \n",
    "            if startTime == \"Closed\" or endTime == \"Closed\" :\n",
    "                continue\n",
    "            else :  \n",
    "                addToDayTimeMap(dayTimeMap, startTime + \",\" + endTime, day)\n",
    "            \n",
    "        \n",
    "        dayAndTimingArray = []\n",
    "        \n",
    "        for startAndEndTime, days in dayTimeMap.items():\n",
    "            \n",
    "            startTime,endTime = startAndEndTime.split(\",\")\n",
    "            openDays = days.split(\",\")\n",
    "            ## Adding Day and Timing\n",
    "            dayAndTiming = {}\n",
    "            dayAndTimingValue = {}\n",
    "            for day in openDays :\n",
    "                dayValue = {}\n",
    "                dayValue[\"value\"] = True\n",
    "                dayAndTimingValue[day] = [dayValue]\n",
    "\n",
    "            timing = {}\n",
    "            timingValue = {}\n",
    "\n",
    "            if startTime and not pd.isnull(startTime): \n",
    "                startTimeDict ={}\n",
    "                startTimeDict[\"value\"] = startTime\n",
    "                timingValue[\"StartTime\"] =  [startTimeDict]\n",
    "\n",
    "            if endTime and not pd.isnull(endTime):\n",
    "                endTimeDict ={}\n",
    "                endTimeDict[\"value\"] = endTime\n",
    "                timingValue[\"EndTime\"] =  [endTimeDict]\n",
    "            \n",
    "            ## Adding day part as \"All Day\"\n",
    "            dayPart ={}\n",
    "            dayPart[\"value\"] = \"All Day\"\n",
    "            timingValue[\"DayPart\"] =  [dayPart]\n",
    "\n",
    "\n",
    "            if timingValue :\n",
    "                timing[\"value\"] = timingValue\n",
    "                dayAndTimingValue[\"Timing\"] = [timing]\n",
    "\n",
    "            if dayAndTimingValue : \n",
    "                dayAndTiming[\"value\"] = dayAndTimingValue    \n",
    "                dayAndTimingArray.append(dayAndTiming)\n",
    "        \n",
    "        hoursOfOperationValue[\"DayAndTiming\"] = dayAndTimingArray\n",
    "        if hoursOfOperationValue :\n",
    "            hoursOfOperation[\"value\"] = hoursOfOperationValue\n",
    "            \n",
    "        hoursOfOperationForEachRow.append(hoursOfOperation)\n",
    "        allHoursOfOperation.append(json.dumps(hoursOfOperationForEachRow))\n",
    "    \n",
    "    return allHoursOfOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineUpscale (dataFrame):\n",
    "    val = \"\"\n",
    "    if dataFrame[\"Upscale/Casual\"] == \"Upscale\":\n",
    "        val = True\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineCasual (dataFrame):\n",
    "    val = \"\"\n",
    "    if dataFrame[\"Upscale/Casual\"] == \"Casual\":\n",
    "        val = True\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineBooleanValueForBar(dataFrame):\n",
    "    val = \"\"\n",
    "    if pd.notnull(dataFrame[\"Bar\"]) :\n",
    "        if dataFrame[\"Bar\"] == \"Yes\":\n",
    "            val = True\n",
    "        elif dataFrame[\"Bar\"].strip() == \"\":\n",
    "            val = \"\"\n",
    "        else:\n",
    "            val = False\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\akk\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Getting the output File name\n",
    "output_fileName = dinningRoom_config['outputFileName']\n",
    "\n",
    "## column index to be increased for getting other Golf Course information\n",
    "columnIndexIncreaseCountFor2ndDining = dinningRoom_config['columnIndexIncreaseCountFor2ndDining']\n",
    "\n",
    "\n",
    "common_column_indexes = []\n",
    "column_names = []\n",
    "\n",
    "## column index for 1st and 2nd \n",
    "columnIndexForFirstDiningRoom = []\n",
    "columnIndexForSecondSecondDiningRoom = []\n",
    "\n",
    "## getting common column information and golf course related column information from config file\n",
    "common_column_count = len(dinningRoom_config['commonColumnInformation'])\n",
    "dining_column_count = len(dinningRoom_config['diningRoomRelatedColumn'])\n",
    "\n",
    "## Getting column index from config json file\n",
    "for i in range(0, common_column_count):\n",
    "    common_column_indexes.append(dinningRoom_config['commonColumnInformation'][i]['columnIndex'])\n",
    "    column_names.append(dinningRoom_config['commonColumnInformation'][i]['outputColumnName'])\n",
    "    \n",
    "for i in range(0, dining_column_count):\n",
    "    columnIndexForFirstDiningRoom.append(dinningRoom_config['diningRoomRelatedColumn'][i]['columnIndex'])\n",
    "    columnIndexForSecondSecondDiningRoom.append(dinningRoom_config['diningRoomRelatedColumn'][i]['columnIndex'] + columnIndexIncreaseCountFor2ndDining)\n",
    "    \n",
    "    column_names.append(dinningRoom_config['diningRoomRelatedColumn'][i]['outputColumnName'])\n",
    "    \n",
    "## getting Hours of Related column information from config file\n",
    "hoursOfOperationInfo = dinningRoom_config['HoursOfOperationInformation']\n",
    "\n",
    "\n",
    "## Data for 1st Golf Course\n",
    "diningRoom1 = surveyData.iloc[:,common_column_indexes + columnIndexForFirstDiningRoom]\n",
    "diningRoom1.columns = column_names\n",
    "\n",
    "diningRoom1['Index']=1\n",
    "\n",
    "hrsOfOperation1 = prepareHoursOfOperationJson(hoursOfOperationInfo, surveyData, True, columnIndexIncreaseCountFor2ndDining)\n",
    "diningRoom1['HrsOfOpeartion'] = hrsOfOperation1\n",
    "\n",
    "\n",
    "## Data for 2nd Golf Course\n",
    "diningRoom2 = surveyData.iloc[:, common_column_indexes + columnIndexForSecondSecondDiningRoom]\n",
    "diningRoom2.columns = column_names\n",
    "\n",
    "diningRoom2['Index']=2\n",
    "\n",
    "hrsOfOperation2 = prepareHoursOfOperationJson(hoursOfOperationInfo, surveyData, False, columnIndexIncreaseCountFor2ndDining)\n",
    "diningRoom2['HrsOfOpeartion'] = hrsOfOperation2\n",
    "\n",
    "## Adding these 3 information together\n",
    "allGolfSurveyData = pd.concat([diningRoom1, diningRoom2])\n",
    "allGolfSurveyData['Status'] = 'Active'\n",
    "allGolfSurveyData['Type'] = 'Dining'\n",
    "\n",
    "\n",
    "## deleting all the rows for which name is blank or, Na or, 0\n",
    "dataExceptBlankName = allGolfSurveyData[(allGolfSurveyData['Name'].str.lower() != 'na') & (allGolfSurveyData['Name'].str.lower() != 'n/a') & (allGolfSurveyData['Name'].notnull()) & (allGolfSurveyData['Name'] != '0')]\n",
    "\n",
    "dataExceptBlankName['Casual'] = dataExceptBlankName.apply(determineCasual, axis=1)\n",
    "dataExceptBlankName['Upscale'] = dataExceptBlankName.apply(determineUpscale, axis=1)\n",
    "dataExceptBlankName['Bar_Boolean'] = dataExceptBlankName.apply(determineBooleanValueForBar, axis=1)\n",
    "\n",
    "dataExceptBlankName.to_csv(\"C:/Projects/MSS/Loading _AmenityData_from_Survey/Python_Codes/ClubCorp/DiningRoom/\" + output_fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
